{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba17fcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wrangle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error,explained_variance_score\n",
    "from sklearn.linear_model import LinearRegression,LassoLars,TweedieRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error,explained_variance_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "425d46dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>year</th>\n",
       "      <th>season</th>\n",
       "      <th>beekeepers</th>\n",
       "      <th>total_loss</th>\n",
       "      <th>average_loss</th>\n",
       "      <th>starting_colonies</th>\n",
       "      <th>colonies_lost</th>\n",
       "      <th>ending_colonies</th>\n",
       "      <th>beekeepers_exclusive_to_state</th>\n",
       "      <th>colonies_exclusive_to_state</th>\n",
       "      <th>ansi</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alabama</td>\n",
       "      <td>2022</td>\n",
       "      <td>annual</td>\n",
       "      <td>33</td>\n",
       "      <td>36.488812</td>\n",
       "      <td>34.260096</td>\n",
       "      <td>316</td>\n",
       "      <td>212</td>\n",
       "      <td>369</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>32.806671</td>\n",
       "      <td>-86.791130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arkansas</td>\n",
       "      <td>2022</td>\n",
       "      <td>annual</td>\n",
       "      <td>18</td>\n",
       "      <td>51.254480</td>\n",
       "      <td>53.867865</td>\n",
       "      <td>152</td>\n",
       "      <td>143</td>\n",
       "      <td>136</td>\n",
       "      <td>94.444444</td>\n",
       "      <td>97.368421</td>\n",
       "      <td>5</td>\n",
       "      <td>34.969704</td>\n",
       "      <td>-92.373123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arkansas</td>\n",
       "      <td>2022</td>\n",
       "      <td>annual</td>\n",
       "      <td>17</td>\n",
       "      <td>49.411765</td>\n",
       "      <td>52.869897</td>\n",
       "      <td>148</td>\n",
       "      <td>126</td>\n",
       "      <td>129</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>34.969704</td>\n",
       "      <td>-92.373123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>california</td>\n",
       "      <td>2022</td>\n",
       "      <td>annual</td>\n",
       "      <td>89</td>\n",
       "      <td>33.269667</td>\n",
       "      <td>42.818791</td>\n",
       "      <td>166009</td>\n",
       "      <td>85526</td>\n",
       "      <td>171543</td>\n",
       "      <td>67.415730</td>\n",
       "      <td>25.320314</td>\n",
       "      <td>6</td>\n",
       "      <td>36.116203</td>\n",
       "      <td>-119.681564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>california</td>\n",
       "      <td>2022</td>\n",
       "      <td>annual</td>\n",
       "      <td>29</td>\n",
       "      <td>36.752854</td>\n",
       "      <td>35.811393</td>\n",
       "      <td>123975</td>\n",
       "      <td>73971</td>\n",
       "      <td>127295</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>36.116203</td>\n",
       "      <td>-119.681564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        state  year  season  beekeepers  total_loss  average_loss  \\\n",
       "0     alabama  2022  annual          33   36.488812     34.260096   \n",
       "1    arkansas  2022  annual          18   51.254480     53.867865   \n",
       "2    arkansas  2022  annual          17   49.411765     52.869897   \n",
       "3  california  2022  annual          89   33.269667     42.818791   \n",
       "4  california  2022  annual          29   36.752854     35.811393   \n",
       "\n",
       "   starting_colonies  colonies_lost  ending_colonies  \\\n",
       "0                316            212              369   \n",
       "1                152            143              136   \n",
       "2                148            126              129   \n",
       "3             166009          85526           171543   \n",
       "4             123975          73971           127295   \n",
       "\n",
       "   beekeepers_exclusive_to_state  colonies_exclusive_to_state  ansi  \\\n",
       "0                     100.000000                   100.000000     1   \n",
       "1                      94.444444                    97.368421     5   \n",
       "2                     100.000000                   100.000000     5   \n",
       "3                      67.415730                    25.320314     6   \n",
       "4                       0.000000                     0.000000     6   \n",
       "\n",
       "    latitude   longitude  \n",
       "0  32.806671  -86.791130  \n",
       "1  34.969704  -92.373123  \n",
       "2  34.969704  -92.373123  \n",
       "3  36.116203 -119.681564  \n",
       "4  36.116203 -119.681564  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = wrangle.bee_merged()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "964a821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_data(df):\n",
    "    '''This function will input dataframe and split into train,validate,test'''\n",
    "    #split dataframw into 80% train  and 20% test \n",
    "    train_validate, test = train_test_split(df, test_size=.2, random_state=825)\n",
    "     #split train further into 75% train, 25% validate\n",
    "    train, validate = train_test_split(train_validate, test_size=.25, random_state=825)\n",
    "    \n",
    "    #return train,validate,test back to function\n",
    "    return train,validate,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a5b3485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((628, 14), (210, 14), (210, 14))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split data\n",
    "train,validate,test = split_data(df)\n",
    "train.shape,validate.shape,test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f2b4a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(train,validate,test,columns):\n",
    "    #make the scaler\n",
    "    scaler = MinMaxScaler()\n",
    "    #fit the scaler at train data only\n",
    "    scaler.fit(train[columns])\n",
    "    #tranforrm train, validate and test\n",
    "    train_scaled = scaler.transform(train[columns])\n",
    "    validate_scaled = scaler.transform(validate[columns])\n",
    "    test_scaled = scaler.transform(test[columns])\n",
    "    \n",
    "    # Generate a list of the new column names with _scaled added on\n",
    "    scaled_columns = [col+\"_scaled\" for col in columns]\n",
    "    \n",
    "    #concatenate with orginal train, validate and test\n",
    "    scaled_train = pd.concat([train.reset_index(drop = True),pd.DataFrame(train_scaled,columns = scaled_columns)],axis = 1)\n",
    "    scaled_validate = pd.concat([validate.reset_index(drop = True),pd.DataFrame(validate_scaled, columns = scaled_columns)], axis = 1)\n",
    "    scaled_test= pd.concat([test.reset_index(drop = True),pd.DataFrame(test_scaled,columns = scaled_columns)],axis = 1)\n",
    "    \n",
    "    return scaled_train,scaled_validate,scaled_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "078fb775",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [col for col in df.drop(columns = [\"state\",\"season\"])]\n",
    "scaled_train,scaled_validate,scaled_test = scale_data(train,validate,test,columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13870035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>year</th>\n",
       "      <th>season</th>\n",
       "      <th>beekeepers</th>\n",
       "      <th>total_loss</th>\n",
       "      <th>average_loss</th>\n",
       "      <th>starting_colonies</th>\n",
       "      <th>colonies_lost</th>\n",
       "      <th>ending_colonies</th>\n",
       "      <th>beekeepers_exclusive_to_state</th>\n",
       "      <th>...</th>\n",
       "      <th>total_loss_scaled</th>\n",
       "      <th>average_loss_scaled</th>\n",
       "      <th>starting_colonies_scaled</th>\n",
       "      <th>colonies_lost_scaled</th>\n",
       "      <th>ending_colonies_scaled</th>\n",
       "      <th>beekeepers_exclusive_to_state_scaled</th>\n",
       "      <th>colonies_exclusive_to_state_scaled</th>\n",
       "      <th>ansi_scaled</th>\n",
       "      <th>latitude_scaled</th>\n",
       "      <th>longitude_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>michigan</td>\n",
       "      <td>2015</td>\n",
       "      <td>annual</td>\n",
       "      <td>206</td>\n",
       "      <td>27.117985</td>\n",
       "      <td>53.774448</td>\n",
       "      <td>7497</td>\n",
       "      <td>2788</td>\n",
       "      <td>7493</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.189463</td>\n",
       "      <td>0.573333</td>\n",
       "      <td>0.021262</td>\n",
       "      <td>0.010846</td>\n",
       "      <td>0.024308</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.787362</td>\n",
       "      <td>0.712385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      state  year  season  beekeepers  total_loss  average_loss  \\\n",
       "0  michigan  2015  annual         206   27.117985     53.774448   \n",
       "\n",
       "   starting_colonies  colonies_lost  ending_colonies  \\\n",
       "0               7497           2788             7493   \n",
       "\n",
       "   beekeepers_exclusive_to_state  ...  total_loss_scaled  average_loss_scaled  \\\n",
       "0                          100.0  ...           0.189463             0.573333   \n",
       "\n",
       "   starting_colonies_scaled  colonies_lost_scaled  ending_colonies_scaled  \\\n",
       "0                  0.021262              0.010846                0.024308   \n",
       "\n",
       "   beekeepers_exclusive_to_state_scaled  colonies_exclusive_to_state_scaled  \\\n",
       "0                                   1.0                                 1.0   \n",
       "\n",
       "   ansi_scaled  latitude_scaled  longitude_scaled  \n",
       "0     0.454545         0.787362          0.712385  \n",
       "\n",
       "[1 rows x 26 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34c6117c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef select_rfe(X,y,  n_features_to_select = 5):\\n    #create the model\\n    rfe=RFE(LinearRegression(), n_features_to_select = n_features_to_select) \\n    #fit the model\\n    rfe.fit(X,y)\\n    #use get_support()\\n    return X.columns[rfe.get_support()]\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def select_rfe(X,y,  n_features_to_select = 5):\n",
    "    #create the model\n",
    "    rfe=RFE(LinearRegression(), n_features_to_select = n_features_to_select) \n",
    "    #fit the model\n",
    "    rfe.fit(X,y)\n",
    "    #use get_support()\n",
    "    return X.columns[rfe.get_support()]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3e9e5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a7e2a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba7ea5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b56a51bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['state', 'year', 'season', 'beekeepers', 'total_loss', 'average_loss',\n",
       "       'starting_colonies', 'colonies_lost', 'ending_colonies',\n",
       "       'beekeepers_exclusive_to_state', 'colonies_exclusive_to_state', 'ansi',\n",
       "       'latitude', 'longitude', 'year_scaled', 'beekeepers_scaled',\n",
       "       'total_loss_scaled', 'average_loss_scaled', 'starting_colonies_scaled',\n",
       "       'colonies_lost_scaled', 'ending_colonies_scaled',\n",
       "       'beekeepers_exclusive_to_state_scaled',\n",
       "       'colonies_exclusive_to_state_scaled', 'ansi_scaled', 'latitude_scaled',\n",
       "       'longitude_scaled'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be04ca09",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaled_train[[col for col in scaled_train.columns if col.endswith(\"scaled\")]]\n",
    "y_train = scaled_train[[\"colonies_lost\"]]\n",
    "X_validate = scaled_validate[[col for col in scaled_validate.columns if col.endswith(\"scaled\")]]\n",
    "y_validate = scaled_validate[[\"colonies_lost\"]]\n",
    "X_test = scaled_test[[col for col in scaled_test.columns if col.endswith(\"scaled\")]]\n",
    "y_test = scaled_test[[\"colonies_lost\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3718499d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_scaled</th>\n",
       "      <th>beekeepers_scaled</th>\n",
       "      <th>total_loss_scaled</th>\n",
       "      <th>average_loss_scaled</th>\n",
       "      <th>starting_colonies_scaled</th>\n",
       "      <th>colonies_lost_scaled</th>\n",
       "      <th>ending_colonies_scaled</th>\n",
       "      <th>beekeepers_exclusive_to_state_scaled</th>\n",
       "      <th>colonies_exclusive_to_state_scaled</th>\n",
       "      <th>ansi_scaled</th>\n",
       "      <th>latitude_scaled</th>\n",
       "      <th>longitude_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.24375</td>\n",
       "      <td>0.189463</td>\n",
       "      <td>0.573333</td>\n",
       "      <td>0.021262</td>\n",
       "      <td>0.010846</td>\n",
       "      <td>0.024308</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.787362</td>\n",
       "      <td>0.712385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.00250</td>\n",
       "      <td>0.373723</td>\n",
       "      <td>0.373659</td>\n",
       "      <td>0.041644</td>\n",
       "      <td>0.048046</td>\n",
       "      <td>0.058165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>0.835024</td>\n",
       "      <td>0.615962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year_scaled  beekeepers_scaled  total_loss_scaled  average_loss_scaled  \\\n",
       "0     0.363636            0.24375           0.189463             0.573333   \n",
       "1     0.727273            0.00250           0.373723             0.373659   \n",
       "\n",
       "   starting_colonies_scaled  colonies_lost_scaled  ending_colonies_scaled  \\\n",
       "0                  0.021262              0.010846                0.024308   \n",
       "1                  0.041644              0.048046                0.058165   \n",
       "\n",
       "   beekeepers_exclusive_to_state_scaled  colonies_exclusive_to_state_scaled  \\\n",
       "0                                   1.0                                 1.0   \n",
       "1                                   0.0                                 0.0   \n",
       "\n",
       "   ansi_scaled  latitude_scaled  longitude_scaled  \n",
       "0     0.454545         0.787362          0.712385  \n",
       "1     0.981818         0.835024          0.615962  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bc23548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_baseline_RMSE(y_train):\n",
    "    '''\n",
    "    this function will calculate baseline mean and baseline median and calculate RMSE from mean and median\n",
    "    '''\n",
    "    #get mean of target from train\n",
    "    y_train[\"baseline_mean\"] = y_train.colonies_lost.mean()\n",
    "    #get median of target from train\n",
    "    y_train[\"baseline_median\"] =y_train.colonies_lost.median()\n",
    "    #get mean of target from validate\n",
    "    y_validate[\"baseline_mean\"] = y_validate.colonies_lost.mean()\n",
    "    #get median from target from validate\n",
    "    y_validate[\"baseline_median\"] =y_validate.colonies_lost.median()\n",
    "    \n",
    "    #calculate RMSE \n",
    "    RMSE_train_mean=mean_squared_error(y_train.colonies_lost,y_train.baseline_mean, squared = False)\n",
    "    RMSE_validate_mean=mean_squared_error(y_validate.colonies_lost,y_validate.baseline_mean, squared = False)\n",
    "\n",
    "    print(\"RMSE using Mean on \\nTrain: \", round(RMSE_train_mean,2), \"\\nValidate: \", round(RMSE_validate_mean,2))\n",
    "    print()\n",
    "\n",
    "    #calculate RMSE\n",
    "    RMSE_train_median= mean_squared_error(y_train.colonies_lost,y_train.baseline_median, squared = False)\n",
    "    RMSE_validate_median= mean_squared_error(y_validate.colonies_lost,y_validate.baseline_median, squared = False)\n",
    "\n",
    "    print(\"RMSE using Median on \\nTrain: \", round(RMSE_train_median,2), \"\\nValidate: \", round(RMSE_validate_median,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3564cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE using Mean on \n",
      "Train:  24889.79 \n",
      "Validate:  22715.23\n",
      "\n",
      "RMSE using Median on \n",
      "Train:  26495.83 \n",
      "Validate:  23859.98\n"
     ]
    }
   ],
   "source": [
    "get_baseline_RMSE(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020afd31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e208e472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(X_train,y_train, X_validate, y_validate):\n",
    "    '''\n",
    "    this function will calculate baseline mean and baseline median and calculate RMSE from mean and median\n",
    "    '''\n",
    "    #get mean of target from train\n",
    "    y_train[\"baseline_mean\"] = y_train.colonies_lost.mean()\n",
    "    #get median of target from train\n",
    "    y_train[\"baseline_median\"] =y_train.colonies_lost.median()\n",
    "    #get mean of target from validate\n",
    "    y_validate[\"baseline_mean\"] = y_validate.colonies_lost.mean()\n",
    "    #get median from target from validate\n",
    "    y_validate[\"baseline_median\"] =y_validate.colonies_lost.median()\n",
    "    \n",
    "    #calculate RMSE \n",
    "    RMSE_train_mean=mean_squared_error(y_train.colonies_lost,y_train.baseline_mean, squared = False)\n",
    "    RMSE_validate_mean=mean_squared_error(y_validate.colonies_lost,y_validate.baseline_mean, squared = False)\n",
    "\n",
    "    #print(\"RMSE using Mean on \\nTrain: \", round(RMSE_train_mean,2), \"\\nValidate: \", round(RMSE_validate_mean,2))\n",
    "    #print()\n",
    "\n",
    "    #calculate RMSE\n",
    "    RMSE_train_median= mean_squared_error(y_train.colonies_lost,y_train.baseline_median, squared = False)\n",
    "    RMSE_validate_median= mean_squared_error(y_validate.colonies_lost,y_validate.baseline_median, squared = False)\n",
    "\n",
    "    #print(\"RMSE using Median on \\nTrain: \", round(RMSE_train_median,2), \"\\nValidate: \", round(RMSE_validate_median,2))\n",
    "    \n",
    "    #make a dataframe to capture model and RMSE \n",
    "    metric_df = pd.DataFrame(data=[\n",
    "            {\n",
    "                'model': 'Baseline', \n",
    "                'RMSE_train': RMSE_train_mean,\n",
    "                'RMSE_validate': RMSE_validate_mean\n",
    "                }\n",
    "            ])\n",
    "    \n",
    "   \n",
    "    \n",
    "    # create the model object\n",
    "    lm = LinearRegression(normalize = True)\n",
    "    # Fit the model\n",
    "    lm.fit(X_train, y_train.colonies_lost)\n",
    "    # Predict y on train\n",
    "    y_train['colonies_lost_pred_lm'] = lm.predict(X_train)\n",
    "    # predict validate\n",
    "    y_validate['colonies_lost_pred_lm'] = lm.predict(X_validate)\n",
    "    \n",
    "    # evaluate: train rmse\n",
    "    rmse_train_lm= round(mean_squared_error(y_train.colonies_lost, y_train.colonies_lost_pred_lm,squared = False), 2)\n",
    "    # evaluate: validate rmse\n",
    "    rmse_validate_lm= round(mean_squared_error(y_validate.colonies_lost, y_validate.colonies_lost_pred_lm,squared = False),2)\n",
    "\n",
    "    #append model and RMSE from OLS model to metric dataframe\n",
    "    metric_df = metric_df.append({\n",
    "    'model': 'OLS Regressor', \n",
    "    'RMSE_train': rmse_train_lm,\n",
    "    'RMSE_validate': rmse_validate_lm,\n",
    "    }, ignore_index=True)\n",
    "    \n",
    "    \n",
    "    # create the model object\n",
    "    lars = LassoLars(alpha=1)\n",
    "    # fit the model.\n",
    "    lars.fit(X_train, y_train.colonies_lost)\n",
    "    # predict train\n",
    "    y_train['colonies_lost_pred_lars'] = lars.predict(X_train)\n",
    "    # predict validate\n",
    "    y_validate['colonies_lost_pred_lars'] = lars.predict(X_validate)\n",
    "    # evaluate: train rmse\n",
    "    rmse_train_lars = round(mean_squared_error(y_train.colonies_lost, y_train.colonies_lost_pred_lars, squared = False),2)\n",
    "    # evaluate: validate rmse\n",
    "    rmse_validate_lars= round(mean_squared_error(y_validate.colonies_lost, y_validate.colonies_lost_pred_lars,squared = False),2)\n",
    "\n",
    "    #append model and RMSE from LASSOLARS model to metric dataframe\n",
    "    metric_df = metric_df.append({\n",
    "    'model': 'LASSOLARS(alpha = 1)', \n",
    "    'RMSE_train': rmse_train_lars,\n",
    "    'RMSE_validate': rmse_validate_lars,\n",
    "    }, ignore_index=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # create the model object\n",
    "    glm = TweedieRegressor(power=1, alpha=0)\n",
    "    # fit the model to our training data.\n",
    "    glm.fit(X_train, y_train.colonies_lost)\n",
    "    # predict train\n",
    "    y_train['colonies_lost_pred_glm'] = glm.predict(X_train)\n",
    "    # predict validate\n",
    "    y_validate['colonies_lost_pred_glm'] = glm.predict(X_validate)\n",
    "    # evaluate: train rmse\n",
    "    rmse_train_tw = round(mean_squared_error(y_train.colonies_lost, y_train.colonies_lost_pred_glm,squared = False),2)\n",
    "    # evaluate: validate rmse\n",
    "    rmse_validate_tw= round(mean_squared_error(y_validate.colonies_lost, y_validate.colonies_lost_pred_glm, squared = False),2)\n",
    "\n",
    "    #append model and RMSE from GLM model to metric dataframe\n",
    "    metric_df = metric_df.append({\n",
    "    'model': 'Tweedie Regressor(power=1, alpha=0)', \n",
    "    'RMSE_train': rmse_train_tw,\n",
    "    'RMSE_validate': rmse_validate_tw,\n",
    "    }, ignore_index=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #create model object\n",
    "    pf= PolynomialFeatures(degree= 5)\n",
    "    # fit and transform X_train_scaled\n",
    "    X_train_degree5 = pf.fit_transform(X_train)\n",
    "    # transform X_validate_scaled \n",
    "    X_validate_degree5 = pf.transform(X_validate)\n",
    "\n",
    "    # create the model object\n",
    "    lm5 = LinearRegression(normalize=True)\n",
    "    # fit the model to our training data. We must specify the column in y_train,  \n",
    "    lm5.fit(X_train_degree5, y_train.colonies_lost)\n",
    "    # predict train\n",
    "    y_train['colonies_lost_pred_lm5'] = lm5.predict(X_train_degree5)\n",
    "    # predict validate\n",
    "    y_validate['colonies_lost_pred_lm5'] = lm5.predict(X_validate_degree5)\n",
    "\n",
    "    # evaluate: train rmse\n",
    "    rmse_train_py= round(mean_squared_error(y_train.colonies_lost, y_train.colonies_lost_pred_lm5, squared = False),2)\n",
    "    # evaluate: validate rmse\n",
    "    rmse_validate_py= round(mean_squared_error(y_validate.colonies_lost, y_validate.colonies_lost_pred_lm5, squared = False) , 2)\n",
    "\n",
    "    #append model and RMSE from Polynomial Regression model to metric dataframe\n",
    "    metric_df = metric_df.append({\n",
    "    'model': 'Polynomial Regression(degree = 5)', \n",
    "    'RMSE_train': rmse_train_py,\n",
    "    'RMSE_validate': rmse_validate_py,\n",
    "    }, ignore_index=True)\n",
    "    \n",
    "    \n",
    "    print(metric_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6991813e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 model    RMSE_train  RMSE_validate\n",
      "0                             Baseline  24889.788974   22715.232721\n",
      "1                        OLS Regressor      0.000000       0.000000\n",
      "2                 LASSOLARS(alpha = 1)     25.060000      22.950000\n",
      "3  Tweedie Regressor(power=1, alpha=0)  10984.540000    9843.510000\n",
      "4    Polynomial Regression(degree = 5)      0.000000    1905.890000\n"
     ]
    }
   ],
   "source": [
    "RMSE(X_train,y_train, X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1afa15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd32e59c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
